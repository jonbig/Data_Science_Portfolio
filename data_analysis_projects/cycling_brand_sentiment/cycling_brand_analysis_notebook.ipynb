{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating reddit instance\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id= client_id,\n",
    "    password=password,\n",
    "    client_secret= secret_key,\n",
    "    user_agent= user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "df = pd.DataFrame(columns=[\"id\", \"title\", \"created\", \"created_utc\", 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting top submissions in the cycling subreddit\n",
    "for submission in reddit.subreddit(\"cycling\").top(limit=None):\n",
    "    df = df.append({\"id\": submission.id, \"title\": submission.title,\"created\": submission.created, \"created_utc\": submission.created_utc, \"score\": submission.score}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate submissions\n",
    "df = df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning UTC column into datetime\n",
    "df['created'] = df['created'].astype('str')\n",
    "df['Converted_Date_2'] = pd.to_datetime(df['created'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterating through the dataframe in order to get all comments attached to each submission id\n",
    "#appending those comments to the dataframe\n",
    "df = pd.DataFrame(columns=[\"id\", \"Comment\"])\n",
    "\n",
    "for id in df:\n",
    "    submission = reddit.submission(id)\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    comment_queue = submission.comments[:] \n",
    "    \n",
    "    while comment_queue:\n",
    "        comment = comment_queue.pop(0)\n",
    "        # Add id and comment.body to the DataFrame\n",
    "        df = df.append({\"id\": id, \"Comment\": comment.body}, ignore_index=True)\n",
    "        comment_queue.extend(comment.replies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a list of bike brands\n",
    "manufacturers = [\n",
    "    \"Giant\", \"Trek\", \"Specialized\", \"Cannondale\", \"Scott\",\n",
    "    \"Santa Cruz\", \"Bianchi\", \"Merida\", \"GT\", \"BMC\", \"Cube\",\n",
    "    \"Kona\", \"Fuji\", \"Orbea\", \"Colnago\", \"Pinarello\", \"Cerv√©lo\", \"Focus\",\n",
    "    \"Rocky Mountain\", \"Wilier\", \"Raleigh\", \"Felt\", \"Yeti\",\n",
    "    \"Marin\", \"Norco\", \"Pivot\", \"Salsa\", \"Ibis\", \"Diamondback\",\n",
    "    \"Devinci\", \"Jamis\", \"Fuji\", \"Ghost\", \"Canyon\", \"Fuji\",\n",
    "    \"Gazelle\", \"Look\", \"Ridley\", \"Santana\", \"Surly\", \"Breezer\",\n",
    "    \"Cinelli\", \"De Rosa\", \"Litespeed\", \"Masi\", \"Scott\", \"Time\",\n",
    "    \"Van Nicholas\", \"Yeti\", \"felt\", \"Eddy Merckx\", 'huffy', 'schwinn', \n",
    "    'transition', 'sixthreezero', 'electra', 'evil', 'niner', 'mongoose', '6ku'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting brands to lowercase\n",
    "manufacturers = [str(word).lower() for word in manufacturers if isinstance(word, str)]\n",
    "manufacturers = list(set(manufacturers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting all comments lowercase\n",
    "df['Comment'] = df['Comment'].apply(lambda x: ' '.join(word.lower() for word in str(x).split()) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting comments that contain any of the bike brands\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        text = row['Comment']\n",
    "        # Check if any of the search words exists in the column\n",
    "        if any(word in text for word in manufacturers):\n",
    "            # Add the row to the matching DataFrame\n",
    "            row['brand'] = next((word for word in manufacturers if word in text), None)\n",
    "            matching_df = matching_df.append(row) \n",
    "                \n",
    "    except TypeError:\n",
    "        pass\n",
    "\n",
    "# Reset the index of the matching DataFrame\n",
    "matching_df = matching_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loops through a dataframe and applies polarity score function to the comment column, then\n",
    "#adds each score (dictionary) to the dataframe\n",
    "\n",
    "for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    try:\n",
    "        comment = row['Comment']\n",
    "        roberta_result = polarity_scores_roberta(comment)\n",
    "\n",
    "        # Assign roberta_result values to specific row in the dataframe\n",
    "        for key, value in roberta_result.items():\n",
    "            df.at[i, key] = value\n",
    "\n",
    "    except RuntimeError:\n",
    "        print('Missed one')\n",
    "\n",
    "    except IndexError:\n",
    "        print('Missed one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending results to csv\n",
    "df.to_csv('all_sentiments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
